{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controlling Simulation Error: Theory and Practice\n",
    "\n",
    "Hands-on techniques to quantify and control error in stochastic simulation: Markov/Chebyshev/Bernstein inequalities, CLT, Markov chain convergence, variance reduction, and error propagation in an M/M/1 queue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "- Apply Markov, Chebyshev, and Bernstein inequalities to bound errors.\n",
    "- Use CLT for CIs and sample-size planning.\n",
    "- Simulate a 3-state Markov chain and assess convergence.\n",
    "- Apply antithetic and control variates to cut variance.\n",
    "- Propagate parameter error to performance metrics in M/M/1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b561c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "def new_rng(seed=None):\n",
    "    return np.random.default_rng(42 if seed is None else seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32bf85f",
   "metadata": {},
   "source": [
    "## Error Control Basics: Key Inequalities\n",
    "- Markov (nonnegative X): $\\mathbb P(X \\ge t) \\le \\mathbb E[X]/t$.\n",
    "- Chebyshev (finite variance): $\\mathbb P(|X-\\mathbb E[X]| \\ge \\varepsilon) \\le \\mathrm{Var}(X)/\\varepsilon^2$.\n",
    "- Bernstein (bounded $|X_i-\\mu| \\le b$ IID, mean $\\bar X_n$): $$\\mathbb P(|\\bar X_n-\\mu| \\ge \\varepsilon) \\le 2\\exp\\Big( - \\frac{n \\varepsilon^2}{2\\sigma^2 + (2/3)b\\varepsilon} \\Big).$$\n",
    "- There are generalization of Bernstein ineequality, for unbounded support, for example Bennnet (sub-exponential; see [Bennett (wiki)](https://en.wikipedia.org/wiki/Bennett%27s_inequality) or [Bernstein (wiki)](https://en.wikipedia.org/wiki/Bernstein_inequalities_(probability_theory))). There is a wide numbner of concentration inequalities available [Concentration Inequalities (wiki)](https://en.wikipedia.org/wiki/Concentration_inequality)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1695620",
   "metadata": {},
   "source": [
    "## CLT and Confidence Intervals\n",
    "For IID with mean $\\mu$, variance $\\sigma^2$: $\\sqrt{n}(\\bar X-\\mu)/\\sigma \\Rightarrow \\mathcal N(0,1)$.\n",
    "- Approx. CI: $\\bar X \\pm z_{1-\\alpha/2} s/\\sqrt{n}$.\n",
    "- Sample size for half-width $\\varepsilon$: $n \\approx (z\\sigma/\\varepsilon)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5101ed81",
   "metadata": {},
   "source": [
    "### CLT Details and Sample Size Planning\n",
    "Let i.i.d. $X$ have mean $\\mu$ and variance $\\sigma^2$. For large $n$, the central limit theorem implies that\n",
    "$\\frac{\\sqrt{n}(\\bar X - \\mu)}{\\sigma} \\Rightarrow \\mathcal N(0,1).$\n",
    "\n",
    "- Two-sided $(1-\\alpha)$ CI with known $\\sigma$:\n",
    "  $ \\bar X \\pm z_{1-\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}. $\n",
    "- Unknown $\\sigma$: replace $\\sigma$ by the sample $s$ and use $z$ (for large $n$) or $t_{n-1}$ for finite $n$.\n",
    "- Target half-width $\\varepsilon$: choose\n",
    "  $ n \\ge \\left( \\frac{z_{1-\\alpha/2}\\, \\sigma}{\\varepsilon} \\right)^2. $\n",
    "  If $\\sigma$ is unknown, use a pilot estimate or Chebyshev/Bernstein for guaranteed bounds.\n",
    "- Relative error: want $|\\bar X-\\mu| \\le r|\\mu|$ with probability $\\approx 1-\\alpha$; then $ n \\ge \\left( \\frac{z\\, \\sigma}{r|\\mu|} \\right)^2. $\n",
    "- Sequential stopping: keep sampling until $ s\\, z/\\sqrt{n} \\le \\varepsilon$ (subject to a maximum $n$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d750be8f",
   "metadata": {},
   "source": [
    "## Example A: Exponential — Tail and Mean Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdb65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm # For the precise CLT calculation\n",
    "\n",
    "# Helper function definition (assuming this setup)\n",
    "def new_rng(seed):\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "def exp_tail_markov_demo(lam=1.0, N=100000, seed=123):\n",
    "    \"\"\"Demonstrates Markov's Inequality for the single Exp(λ) variable tail.\"\"\"\n",
    "    rng = new_rng(seed)\n",
    "    x = rng.exponential(1/lam, size=N)\n",
    "    ts = np.linspace(0.1, 5.0, 50)\n",
    "    emp = [(x >= t).mean() for t in ts]\n",
    "    markov = [(1/lam)/t for t in ts]\n",
    "    lam_est = 1/x.mean()\n",
    "    markov_est = [(1/lam_est)/t for t in ts]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(ts, emp, label='Empirical P(X≥t)')\n",
    "    plt.plot(ts, markov, label='Markov bound E[X]/t', linestyle='--')\n",
    "    plt.plot(ts, markov_est, label='Markov bound (est)', linestyle=':')\n",
    "    plt.ylim(1e-3, 1); plt.yscale('log')\n",
    "    plt.xlabel('t'); plt.ylabel('Tail probability (log)')\n",
    "    plt.title('Exp(λ) tail vs Markov bound (λ known or estimated)'); plt.legend()\n",
    "\n",
    "\n",
    "# EXECUTION SNIPPET\n",
    "exp_tail_markov_demo(1.0)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb21396",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_mean_clt_chebyshev_demo(lam=1.0, n=50, reps=1_000, eps=0.2, seed=789):\n",
    "    \"\"\"\n",
    "    Compares Empirical, Chebyshev, and CLT bounds for P(|X̄−μ|≥ε).\n",
    "    \"\"\"\n",
    "    rng = new_rng(seed)\n",
    "    samples = rng.exponential(1/lam, size=(reps, n))\n",
    "    means = samples.mean(1)\n",
    "    \n",
    "    # Exponential Distribution Parameters\n",
    "    mu = 1/lam              # E[X] = 1/λ\n",
    "    sigma2 = 1/lam**2       # Var[X] = 1/λ²\n",
    "    \n",
    "    # 1. Empirical Probability\n",
    "    emp = np.mean(np.abs(means - mu) >= eps)\n",
    "    \n",
    "    # 2. Chebyshev Bound\n",
    "    chebyshev_bound = sigma2 / (n * eps**2)\n",
    "    \n",
    "    # 3. CLT Approximation\n",
    "    # Standard deviation of the sample mean: SD(X̄) = sqrt(σ²/n)\n",
    "    sigma_bar = np.sqrt(sigma2 / n)\n",
    "    # P(|X̄−μ|≥ε) ≈ P(|Z| ≥ z), where z = ε / SD(X̄)\n",
    "    z = eps / sigma_bar\n",
    "    # 2 * (1 - CDF(z)) = 2 * Survival Function (z)\n",
    "    clt_approx = 2 * norm.sf(z) \n",
    "    \n",
    "    print(\"--- CLT & Chebyshev Comparison Demo ---\")\n",
    "    print(f'Empirical P(|X̄−μ|≥{eps:.3f}) ≈ {emp:.4f}')\n",
    "    print(f'Chebyshev bound (loose)        ≤ {chebyshev_bound:.4f}')\n",
    "    print(f'CLT approximation (tight)      ≈ {clt_approx:.4f}')\n",
    "    \n",
    "    # Plotting: Same plot as Chebyshev, but titled for comparison\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(means, bins=60, density=True, alpha=0.6, label='X̄ histogram')\n",
    "    plt.axvline(mu, color='k', lw=1, label='μ=1/λ')\n",
    "    plt.axvline(mu-eps, color='r', lw=1, linestyle='--', label='μ±ε')\n",
    "    plt.axvline(mu+eps, color='r', lw=1, linestyle='--')\n",
    "    plt.title(f'Sample mean of Exp(λ) for n={n}: CLT vs Chebyshev'); plt.legend()\n",
    "\n",
    "exp_mean_clt_chebyshev_demo(1.0, n=50, eps=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03b51a",
   "metadata": {},
   "source": [
    "## Example B: Bernstein on Bernoulli (bounded)\n",
    "Compare Chebyshev vs CLT vs Bernstein for target absolute error and confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b1925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log, ceil\n",
    "from scipy.stats import norm # The package for the normal distribution\n",
    "\n",
    "def bernoulli_sample_size_scipy(p=0.3, eps=0.02, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Calculates the required sample size for Bernoulli mean estimation \n",
    "    using Chebyshev, CLT (with SciPy for quantile), and Bernstein bounds.\n",
    "    \"\"\"\n",
    "    sigma2 = p * (1 - p)\n",
    "    \n",
    "    # 1. Chebyshev Bound\n",
    "    n_cheb = ceil(sigma2 / (eps**2 * alpha))\n",
    "    \n",
    "    # 2. CLT (Central Limit Theorem) Bound\n",
    "    # z is the standard normal critical value for a two-sided (1 - alpha) CI.\n",
    "    # We use norm.ppf(1 - alpha/2) to get z_alpha/2.\n",
    "    z = norm.ppf(1 - alpha / 2) \n",
    "    n_clt = ceil((z**2 * sigma2) / (eps**2))\n",
    "    \n",
    "    # 3. Bernstein Bound (for bounded variables)\n",
    "    b = 1.0 # Bounded range [0, 1] -> b = 1\n",
    "    denom = 2 * sigma2 + (2 / 3) * b * eps\n",
    "    n_bern = ceil((denom / eps**2) * np.log(2 / alpha))\n",
    "    \n",
    "    return n_cheb, n_clt, n_bern\n",
    "\n",
    "# Parameters\n",
    "p, eps, alpha = 0.3, 0.02, 0.05\n",
    "\n",
    "# Calculate and print results\n",
    "n_cheb, n_clt, n_bern = bernoulli_sample_size_scipy(p, eps, alpha)\n",
    "\n",
    "# The critical value z for the CLT calculation\n",
    "z_precise = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "print(f\"Standard Normal Quantile (z_0.025: {z_precise:.4f}\")\n",
    "print(\"-\" * 55)\n",
    "print(f'Sample size for Bernoulli mean within ±{eps} with 95% conf.:')\n",
    "print(f'  Chebyshev: {n_cheb}')\n",
    "print(f'  CLT (precise): {n_clt}')\n",
    "print(f'  Bernstein: {n_bern}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb42db",
   "metadata": {},
   "source": [
    "## Three-State Markov Chain: Convergence to Stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df8047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper function definition (assuming this setup)\n",
    "def new_rng(seed):\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "def stationary_distribution(P):\n",
    "    \"\"\"\n",
    "    Computes the stationary distribution (π) of a Markov transition matrix P.\n",
    "    π is the left eigenvector of P corresponding to the eigenvalue 1 (i.e., πP = π).\n",
    "    This is equivalent to the right eigenvector of P.T corresponding to the eigenvalue 1.\n",
    "    \"\"\"\n",
    "    # 1. Compute eigenvalues (w) and right eigenvectors (v) of P.T\n",
    "    w, v = np.linalg.eig(P.T)\n",
    "    \n",
    "    # 2. Find the index (idx) of the eigenvalue closest to 1.0\n",
    "    idx = np.argmin(np.abs(w - 1.0))\n",
    "    \n",
    "    # 3. Get the corresponding eigenvector (pi)\n",
    "    pi = v[:, idx]\n",
    "    \n",
    "    # 4. Use the absolute value of components and ensure they are real (as pi must be real)\n",
    "    # This is the crucial fix for robustness against negative components of the eigenvector\n",
    "    pi = np.abs(np.real(pi)) \n",
    "    \n",
    "    # 5. Normalize the eigenvector to form the probability distribution\n",
    "    pi = pi / pi.sum()\n",
    "    return pi\n",
    "\n",
    "def simulate_markov_chain(P, N=10_000, x0=0, seed=123):\n",
    "    \"\"\"Simulates a Markov Chain for N steps.\"\"\"\n",
    "    rng = new_rng(seed); P = np.asarray(P); K = P.shape[0]\n",
    "    states = np.empty(N, dtype=int); x = x0\n",
    "    for t in range(N):\n",
    "      states[t] = x; x = rng.choice(K, p=P[x])\n",
    "    return states\n",
    "\n",
    "# --- Execution ---\n",
    "P = np.array([[0.6, 0.3, 0.1],\n",
    "              [0.2, 0.5, 0.3],\n",
    "              [0.1, 0.4, 0.5]])\n",
    "\n",
    "# Calculate stationary distribution\n",
    "pi = stationary_distribution(P)\n",
    "\n",
    "# Simulate the Markov Chain\n",
    "states = simulate_markov_chain(P, N=100_000, x0=0)\n",
    "\n",
    "# Calculate L1 distance convergence over time\n",
    "Ts = np.arange(1000, len(states)+1, 1000)\n",
    "dists = []\n",
    "for T in Ts:\n",
    "    counts = np.bincount(states[:T], minlength=P.shape[0])\n",
    "    emp = counts / counts.sum()\n",
    "    dists.append(np.sum(np.abs(emp - pi)))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(Ts, dists)\n",
    "plt.xlabel('Time T'); plt.ylabel(r'L1 distance to $\\pi$')\n",
    "plt.title(r'Convergence of empirical distribution to $\\pi$'); plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print('Stationary π ≈', np.round(pi, 4))\n",
    "final_emp = np.bincount(states, minlength=P.shape[0])/len(states)\n",
    "print('Final empirical ≈', np.round(final_emp, 4))\n",
    "print('L1 distance:', np.round(np.sum(np.abs(final_emp - pi)), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc2e575",
   "metadata": {},
   "source": [
    "To decide how long to run the simulation (i.e., choose the sample size $N$), we need an error bound on the difference between the empirical distribution $\\hat \\pi_n$​ and the true stationary distribution $\\pi$.\n",
    "\n",
    "For a Markov Chain, the relevant concentration inequalities are slightly more complex than for independent and identically distributed (i.i.d.) random variables, but they build on similar concepts. The convergence of the empirical mean (the stationary distribution) is often governed by a version of the Central Limit Theorem (CLT) or Hoeffding/Chernoff-type bounds adapted for dependence.\n",
    "\n",
    "The simulation of an ergodic Markov Chain requires two sequential phases to ensure the validity and precision of the stationary distribution ($\\pi$) estimation: a **burn-in period** and a subsequent **sampling period**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec17f1ee",
   "metadata": {},
   "source": [
    "## Phase 1: Determining the Burn-in Period ($N_{\\text{burn-in}}$)\n",
    "\n",
    "The burn-in period (or warm-up phase) ensures the Markov Chain has sufficiently **mixed**, meaning it has \"forgotten\" its arbitrary starting state and is now sampling from a distribution very close to the stationary distribution ($\\pi$).\n",
    "\n",
    "### Key Concept: Mixing Time ($N_{\\text{mix}}$)\n",
    "\n",
    "The burn-in length is determined by the chain's **Mixing Time ($N_{\\text{mix}}$)**. $N_{\\text{mix}}$ is the minimum number of steps $t$ required for the chain's distribution to be within a small $\\epsilon$ distance of $\\pi$, typically defined using the **Total Variation Distance (TVD)**:\n",
    "$$N_{\\text{mix}}(\\epsilon) = \\min \\left\\{ n \\ge 0 \\mid \\max_{x_0} \\| P^n(x_0, \\cdot) - \\pi(\\cdot) \\|_{\\text{TV}} \\le \\epsilon \\right\\}$$\n",
    "\n",
    "### Practical Determination of $N_{\\text{burn-in}}$\n",
    "\n",
    "1.  **Visual Estimation:** Run a pilot simulation and inspect the plot of $L_1$ distance (which is $2 \\times$ TVD) versus time $T$. The estimated $N_{\\text{mix}}$ is the time $T$ after which the distance plot **flattens out** below a small threshold (e.g., $L_1 \\le 0.2$). \n",
    "2.  **Set Burn-in:** The burn-in period $N_{\\text{burn-in}}$ is set to a conservative multiple of the estimated mixing time. **All samples generated during these steps must be discarded.**\n",
    "    $$N_{\\text{burn-in}} \\approx 5 \\times N_{\\text{mix}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680160cc",
   "metadata": {},
   "source": [
    "## Phase 2: Determining the Sampling Period ($N_{\\text{sample}}$)\n",
    "\n",
    "The sampling period determines how many steps ($N_{\\text{sample}}$) are needed *after* burn-in to achieve a desired **precision ($\\epsilon$)** with a target **confidence ($1-\\alpha$)** for the empirical distribution $\\hat{\\pi}_{N_{\\text{sample}}}$.\n",
    "\n",
    "### Approach A: Hoeffding-Type Bound (Rigorous $N_{\\text{sample}}$)\n",
    "\n",
    "This method provides a rigorous *a priori* bound on the required sample size, directly integrating the mixing time.\n",
    "\n",
    "The concentration inequality for the empirical stationary measure $\\hat{\\pi}_N(i)$ is structured as:\n",
    "$$\\mathbb{P}\\left(\\max_{i} \\left|\\hat{\\pi}_N(i) - \\pi(i)\\right| \\ge \\epsilon\\right) \\le \\alpha$$\n",
    "\n",
    "To guarantee the error is bounded by $\\epsilon$ for all $K$ states with probability $1-\\alpha$, the required sampling length is:\n",
    "\n",
    "$$N_{\\text{sample}} \\approx \\frac{C \\cdot N_{\\text{mix}}}{\\epsilon^2} \\ln\\left(\\frac{2K}{\\alpha}\\right)$$\n",
    "\n",
    "Where:\n",
    "* $K$ is the number of states.\n",
    "* $C$ is a constant related to the variance (often $C \\approx 2$).\n",
    "* $N_{\\text{mix}}$ acts as the **BoundFactor**, correcting for the dependence by relating $N_{\\text{sample}}$ to the **Effective Sample Size ($N_{\\text{eff}} \\approx N_{\\text{sample}}/N_{\\text{mix}}$)**.\n",
    "\n",
    "### Approach B: CLT-Based Approach (Asymptotic Estimation)\n",
    "\n",
    "The CLT approach provides the asymptotically tightest estimate for the error, but it requires the **asymptotic variances** ($\\sigma^2_i$), which is challenging to know *a priori*.\n",
    "\n",
    "For large $N$, the estimator $\\hat{\\pi}_N(i)$ is approximately normally distributed:\n",
    "$$\\hat{\\pi}_N(i) \\approx \\mathcal{N}\\left(\\pi(i), \\frac{\\sigma^2_i}{N}\\right)$$\n",
    "\n",
    "To achieve a precision $\\epsilon$ with $1-\\alpha$ confidence for a single state $i$:\n",
    "$$N_{\\text{sample}}(i) \\approx \\frac{z_{\\alpha/2}^2 \\cdot \\sigma^2_i}{\\epsilon^2}$$\n",
    "\n",
    "#### The Role of Mixing Time in the CLT\n",
    "\n",
    "The mixing time is **implicitly crucial** to the CLT approach, as the asymptotic variance $\\sigma^2_i$ is inflated by the chain's autocorrelation:\n",
    "$$\\sigma^2_i = \\underbrace{\\pi(i)(1-\\pi(i))}_{\\text{i.i.d. variance}} + \\underbrace{2 \\sum_{t=1}^{\\infty} \\text{Cov}(X_0, X_t)}_{\\text{Dependence Term}}$$\n",
    "The decay rate of the covariance terms is governed by the mixing rate (related to $N_{\\text{mix}}$). **In practice, $\\sigma^2_i$ must be estimated from the collected data (e.g., using batch means) after the burn-in period.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adf8f0f",
   "metadata": {},
   "source": [
    "# Study of a Finite-State Markov Model\n",
    "\n",
    "This analysis examines the properties of the given three-state Markov Chain (MC) to determine its stationary distribution and calculate the necessary simulation length for accurate estimation.\n",
    "\n",
    "The transition matrix $P$ is:\n",
    "$$P = \\begin{pmatrix} 0.6 & 0.3 & 0.1 \\\\ 0.2 & 0.5 & 0.3 \\\\ 0.1 & 0.4 & 0.5 \\end{pmatrix}$$\n",
    "\n",
    "***\n",
    "\n",
    "## 1. Model Properties and Stationary Distribution\n",
    "\n",
    "### A. Ergodicity\n",
    "The transition matrix $P$ is **irreducible** (all states can reach all other states) and **aperiodic** (since $P_{i,i} > 0$ for all states). Therefore, the chain is **ergodic**, which guarantees the existence of a unique stationary distribution ($\\pi$) and ensures that the empirical time average converges to the true stationary mean.\n",
    "\n",
    "### B. Stationary Distribution ($\\pi$)\n",
    "The stationary distribution $\\pi$ is the unique probability vector satisfying $\\pi P = \\pi$.\n",
    "\n",
    "| Method | Result ($\\pi$) |\n",
    "| :--- | :--- |\n",
    "| **Eigenvector Method** | $\\pi \\approx [0.2791, 0.4070, 0.3139]$ |\n",
    "\n",
    "The chain spends approximately $27.91\\%$ of its time in State 0, $40.70\\%$ in State 1, and $31.39\\%$ in State 2.\n",
    "\n",
    "***\n",
    "\n",
    "## 2. Convergence Analysis and Burn-in\n",
    "\n",
    "### A. Mixing Time ($N_{\\text{mix}}$)\n",
    "The convergence rate is governed by the magnitude of the **second-largest eigenvalue ($|\\lambda_2|$)** of $P$. More precisely, the mixing time is proportional to $1/(1- |\\lambda_2| )$ for a reversible Markov Chain. \n",
    "* **Eigenvalues:** $\\lambda_1 = 1.0$, $|\\lambda_2| \\approx 0.4414$, $|\\lambda_3| \\approx 0.1586$.\n",
    "* **Conclusion:** The chain exhibits **very fast mixing**. We conservatively, as the chain is not reversible, estimate the mixing time to be **$N_{\\text{mix}} \\approx 50$ steps**.\n",
    "\n",
    "### B. Burn-in Period ($N_{\\text{burn-in}}$)\n",
    "We set the burn-in period to safely discard initial samples influenced by the starting state:\n",
    "\n",
    "$$N_{\\text{burn-in}} = 5 \\times N_{\\text{mix}} = 5 \\times 50 = \\mathbf{250 \\text{ steps}}$$\n",
    "\n",
    "***\n",
    "\n",
    "## 3. Determining the Sampling Period ($N_{\\text{sample}}$)\n",
    "\n",
    "We calculate the required sampling period to achieve a target precision $\\epsilon$ with $1-\\alpha$ confidence for all $K=3$ states.\n",
    "\n",
    "**Target Parameters:**\n",
    "* **Precision ($\\epsilon$):** $0.01$ (Maximum error on $\\hat{\\pi}_i$)\n",
    "* **Confidence ($1-\\alpha$):** $0.95$ ($\\alpha=0.05$)\n",
    "* **Z-score:** $z_{0.025} \\approx 1.96$\n",
    "\n",
    "### A. Hoeffding-Type Bound (Worst-Case Guarantee)\n",
    "\n",
    "This provides a loose but guaranteed **worst-case upper bound**, correcting for dependence using $N_{\\text{mix}}$.\n",
    "\n",
    "$$N_{\\text{sample}}^{\\text{Hoeffding}} \\approx \\frac{C \\cdot N_{\\text{mix}}}{\\epsilon^2} \\ln\\left(\\frac{2K}{\\alpha}\\right) \\approx \\mathbf{479,000 \\text{ steps}}$$\n",
    "\n",
    "### B. CLT-Based Approach (A Priori, Guaranteed Bound)\n",
    "\n",
    "The CLT approach requires the **asymptotic variance ($\\sigma^2_i$)** of the sample mean. We derive a guaranteed upper bound on $\\sigma^2_i$ using the **Spectral Gap**, the difference between the largest eigenvalue (1) and the second-largest ($|\\lambda_2|$). This technique yields the best possible theoretical *a priori* bound for this specific chain.\n",
    "\n",
    "1.  **Define Variance Bound ($\\sigma^2_{\\text{bound}}$):** The maximum inflation factor for the variance due to dependence is bounded by the term $\\frac{1 + |\\lambda_2|}{1 - |\\lambda_2|}$.\n",
    "    $$\\sigma^2_{\\text{bound}} \\le \\frac{1 + |\\lambda_2|}{1 - |\\lambda_2|} \\cdot V_{\\text{i.i.d.}}(i)$$\n",
    "    Where $V_{\\text{i.i.d.}}(i) = \\pi_i(1-\\pi_i)$ is the i.i.d. variance. This result is true for reversible chains, but remains a valid upper bound in many cases.\n",
    "\n",
    "2.  **Calculate $\\sigma^2_{\\text{bound}}$ (State 1):** We use the most uncertain state ($\\pi_1 \\approx 0.4070$) where $V_{\\text{i.i.d.}} \\approx 0.2413$.\n",
    "    $$\\text{Max Inflation Factor} \\approx \\frac{1 + 0.4414}{1 - 0.4414} \\approx 2.58$$\n",
    "    $$\\sigma^2_{\\text{bound}} \\approx 2.58 \\times 0.2413 \\approx 0.622$$\n",
    "\n",
    "3.  **Required $N_{\\text{CLT}}$ (A Priori Bound):** The sample size is calculated using the standard CLT formula with the variance upper bound $\\sigma^2_{\\text{bound}}$.\n",
    "    $$N_{\\text{CLT}}^{\\text{bound}} \\approx \\frac{z_{0.025}^2 \\cdot \\sigma^2_{\\text{bound}}}{\\epsilon^2} = \\frac{(1.96)^2 \\cdot 0.622}{(0.01)^2} \\approx \\mathbf{23,900 \\text{ steps}}$$\n",
    "\n",
    "***\n",
    "\n",
    "## 4. Conclusion and Final Experiment Length\n",
    "\n",
    "The **A Priori CLT bound ($\\mathbf{23,900}$ steps)** provides the tightest upper limit for the required sample size without needing a pilot simulation.\n",
    "\n",
    "| Bound | Required $N_{\\text{sample}}$ | Implication |\n",
    "| :--- | :--- | :--- |\n",
    "| **Hoeffding** | $479,000$ | **Worst-Case Guarantee** (Highly conservative). |\n",
    "| **CLT (A Priori)** | $\\mathbf{23,900}$ | **Guaranteed Upper Limit** for this specific MC (using spectral gap). |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b6649",
   "metadata": {},
   "source": [
    "## Introduction to Variance Reduction in Simulations\n",
    "\n",
    "Monte Carlo simulations estimate quantities like expectations or integrals by averaging random samples. However, high variance in these estimates can lead to imprecise results, requiring many samples and increasing computational cost. **Variance reduction techniques** lower the variance of estimators without introducing bias, allowing accurate results with fewer samples. This is crucial for efficient simulations in applications like financial modeling or queueing systems.\n",
    "\n",
    "This section explains two common variance reduction techniques—**antithetic variates** and **control variates**—using the example of estimating the integral of $e^{-x}$ from 0 to 1, which equals $1 - e^{-1} \\approx 0.632$.\n",
    "\n",
    "## Why Variance Reduction?\n",
    "\n",
    "Monte Carlo methods estimate an expected value, such as $E[f(X)]$, using the sample mean $\\tfrac1n \\sum_{i=1}^n f(X_i)$, where $X_i$ are random samples (e.g., $X_i \\sim \\text{Uniform}(0,1)$). The variance of this estimator is $\\text{Var}(f(X))/n$. High variance leads to wider confidence intervals and less precise estimates. Variance reduction techniques reduce $\\text{Var}(\\tfrac1n \\sum_{i=1}^n f(X_i))$, enabling accurate estimates with a smaller $n$.\n",
    "\n",
    "## Variance Reduction Techniques\n",
    "\n",
    "### 1. Antithetic Variates\n",
    "\n",
    "**Idea**: Antithetic variates exploit negative correlation between paired samples to reduce variance. For a random variable $X_i \\sim \\text{Uniform}(0,1)$, we pair it with $1 - X_i$, which is also $\\text{Uniform}(0,1).$ The estimator for $E[f(X)]$ is:\n",
    "\n",
    "$\\frac{1}{\\tfrac{n}2} \\sum_{i=1}^{n/2} (f(X_i) + f(1 - X_i))/2$.\n",
    "\n",
    "This works well for monotone functions (e.g., increasing or decreasing), as $f(X_i)$ and $f(1 - X_i)$ are negatively correlated, reducing the variance of their average.\n",
    "\n",
    "**Example**: To estimate the integral of $e^{-x}$ from 0 to 1, we sample $U_i \\sim \\text{Uniform}(0,1)$ and compute $(1/(n/2)) \\sum_{i=1}^{n/2} (e^{-U_i} + e^{-(1 - U_i)})/2$. Since $e^{-x}$ is decreasing, $e^{-U_i}$ and $e^{-(1 - U_i)}$ have negative correlation, lowering variance compared to the naive estimate $(1/n) \\sum_{i=1}^n e^{-U_i}$.\n",
    "\n",
    "**Why It Works**: The variance of the antithetic estimator is:\n",
    "\n",
    "$(1/4) [\\text{Var}(f(U)) + \\text{Var}(f(1 - U)) + 2 \\text{Cov}(f(U), f(1 - U))]$.\n",
    "\n",
    "Since $\\text{Var}(f(1 - U)) = \\text{Var}(f(U))$ and $\\text{Cov}(f(U), f(1 - U))$ is negative for monotone $f$, the variance is smaller than $\\text{Var}(f(U))/n$ for the naive estimator.\n",
    "\n",
    "### 2. Control Variates\n",
    "\n",
    "**Idea:** Control variates improve the estimate of an unknown quantity by using a related quantity with a known expected value. Suppose we want to estimate $E[m] = \\mu$, where $m$ is an unbiased estimator (e.g., $m = (1/n) \\sum_{i=1}^n f(X_i)$ for $f(X_i) = e^{-X_i}$). We choose a control variate $t$ with known expected value $E[t] = \\tau$ (e.g., $t = (1/n) \\sum_{i=1}^n X_i$, $\\tau = 0.5$ for $X_i \\sim \\text{Uniform}(0,1)$). The control variate estimator is:\n",
    "\n",
    "$m^* = m + c (t - \\tau)$,\n",
    "\n",
    "where $c$ is a constant chosen to minimize variance. This estimator remains unbiased because $E[m^*] = E[m] + c (E[t] - \\tau) = \\mu + c (\\tau - \\tau) = \\mu$.\n",
    "\n",
    "The variance of $m^*$ is:\n",
    "\n",
    "$\\text{Var}(m^*) = \\text{Var}(m) + c^2 \\text{Var}(t) + 2c \\text{Cov}(m, t)$.\n",
    "\n",
    "To minimize $\\text{Var}(m^*)$, we choose the optimal coefficient:\n",
    "\n",
    "$c^* = -\\text{Cov}(m, t) / \\text{Var}(t)$.\n",
    "\n",
    "This gives the minimum variance:\n",
    "\n",
    "$\\text{Var}(m^*) = \\text{Var}(m) (1 - \\rho_{m,t}^2)$,\n",
    "\n",
    "where $\\rho_{m,t} = \\text{Corr}(m, t)$ is the correlation between $m$ and $t$. The closer $|\\rho_{m,t}|$ is to 1, the greater the variance reduction.\n",
    "\n",
    "**Example:** To estimate the integral of $e^{-x}$ from 0 to 1, we use $m = (1/n) \\sum_{i=1}^n e^{-X_i}$, where $X_i \\sim \\text{Uniform}(0,1)$. We choose the control variate $t = (1/n) \\sum_{i=1}^n X_i$, with known $E[t] = 0.5$. We estimate $c^* = -\\text{Cov}(e^{-X}, X) / \\text{Var}(X)$ from samples and compute:\n",
    "\n",
    "$m^* = (1/n) \\sum_{i=1}^n e^{-X_i} + c^* ((1/n) \\sum_{i=1}^n X_i - 0.5)$.\n",
    "\n",
    "Since $e^{-X}$ and $X$ are correlated (as $e^{-x}$ decreases with $x$), this reduces variance compared to the naive estimate.\n",
    "\n",
    "**Practical Notes:** In practice, $\\text{Cov}(m, t)$ and $\\text{Var}(t)$ are estimated from the same samples used for $m$ and $t$, equivalent to a linear regression of $m$ on $t$. This method is effective when $t$ is cheap to compute and highly correlated with $m$. For the integral of $e^{-x}$, the control variate $X$ is simple and effective, reducing variance significantly.\n",
    "\n",
    "## Practical Impact\n",
    "\n",
    "For the integral of $e^{-x}$ from 0 to 1, simulations with $n = 10000$ samples show:\n",
    "- **Naive Monte Carlo**: Higher variance, less precise estimates.\n",
    "- **Antithetic Variates**: Reduced variance due to negative correlation, effective for the decreasing $e^{-x}$.\n",
    "- **Control Variates**: Further variance reduction when $e^{-X}$ and $X$ are correlated.\n",
    "\n",
    "We see this in the following code snippet. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2cfa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simple RNG factory for reproducibility\n",
    "def new_rng(seed):\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "# ----------------------------\n",
    "# Monte Carlo for I = ∫_0^1 e^{-u} du\n",
    "# ----------------------------\n",
    "def estimate_integral_variants(n=1_000, reps=200, seed=321):\n",
    "    \"\"\"\n",
    "    Estimate I = ∫_0^1 e^{-u} du = 1 - e^{-1} by three standard MC estimators:\n",
    "      - Naive:        Î = mean(e^{-U}),          U ~ Unif(0,1)\n",
    "      - Antithetic:   Î = mean(0.5*(e^{-U} + e^{-(1-U)})) using m = ⌊n/2⌋ pairs\n",
    "      - Control var.: Î = mean(f) - β̂ ( mean(g) - 1/2 ), with g(U)=U and\n",
    "                       β̂ = Cov(f,g) / Var(g), f(U)=e^{-U}\n",
    "    \n",
    "    Prints mean, sd, bias of each estimator across 'reps' replications,\n",
    "    and variance ratios vs the naive estimator. Also shows a histogram comparison.\n",
    "    Returns a small dict with values and summary stats.\n",
    "    \"\"\"\n",
    "    rng = new_rng(seed)\n",
    "    true_I = 1.0 - np.exp(-1.0)\n",
    "\n",
    "    est_naive, est_anti, est_cv = [], [], []\n",
    "\n",
    "    for _ in range(reps):\n",
    "        # Draw uniforms once per replication\n",
    "        U  = rng.random(n)\n",
    "        fU = np.exp(-U)          # f(U) = e^{-U}\n",
    "\n",
    "        # Naive estimator\n",
    "        est_naive.append(fU.mean())\n",
    "\n",
    "        # Antithetic variates: pair U with 1-U\n",
    "        m = n // 2\n",
    "        Uhalf = U[:m]\n",
    "        fA = 0.5 * (np.exp(-Uhalf) + np.exp(-(1.0 - Uhalf)))\n",
    "        est_anti.append(fA.mean())\n",
    "\n",
    "        # Control variates with g(U)=U, E[g]=1/2\n",
    "        gU = U\n",
    "        cov_fg = np.cov(fU, gU, bias=True)[0, 1]  # population (bias=True) for stability at large n\n",
    "        var_g  = np.var(gU)\n",
    "        beta_hat = cov_fg / var_g\n",
    "        est_cv.append(fU.mean() - beta_hat * (gU.mean() - 0.5))\n",
    "\n",
    "    # Collect to arrays\n",
    "    est_naive = np.array(est_naive)\n",
    "    est_anti  = np.array(est_anti)\n",
    "    est_cv    = np.array(est_cv)\n",
    "\n",
    "    # Pretty printer (mean/sd/bias)\n",
    "    def summarize(name, arr):\n",
    "        mean = float(arr.mean())\n",
    "        sd   = float(arr.std(ddof=1))\n",
    "        bias = mean - true_I\n",
    "        print(f\"{name:12s} mean={mean:.6f}  sd={sd:.6f}  bias={bias:.2e}\")\n",
    "        return {\"mean\": mean, \"sd\": sd, \"bias\": bias}\n",
    "\n",
    "    print(\"=== Variance reduction for I = ∫_0^1 e^{-u} du ===\")\n",
    "    print(f\"true I = {true_I:.6f},  n = {n},  reps = {reps}\")\n",
    "\n",
    "    sum_naive = summarize(\"Naive\",       est_naive)\n",
    "    sum_anti  = summarize(\"Antithetic\",  est_anti)\n",
    "    sum_cv    = summarize(\"ControlVar\",  est_cv)\n",
    "\n",
    "    # Variance ratios (smaller is better)\n",
    "    var_ratio_anti = est_anti.var(ddof=1) / est_naive.var(ddof=1)\n",
    "    var_ratio_cv   = est_cv.var(ddof=1)   / est_naive.var(ddof=1)\n",
    "\n",
    "    print(f\" Var ratio anti/naive ≈ {var_ratio_anti:.3f}\")\n",
    "    print(f\"Var ratio  cv/naive ≈ {var_ratio_cv:.3f}\")\n",
    "\n",
    "    # Histogram comparison near the true value\n",
    "    plt.figure()\n",
    "    bins = np.linspace(true_I - 0.05, true_I + 0.05, 40)\n",
    "    plt.hist(est_naive, bins=bins, alpha=0.5, label=\"Naive\")\n",
    "    plt.hist(est_anti,  bins=bins, alpha=0.5, label=\"Antithetic\")\n",
    "    plt.hist(est_cv,    bins=bins, alpha=0.5, label=\"Control variate\")\n",
    "    plt.axvline(true_I, linewidth=1, label=\"True I\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Variance reduction comparison\")\n",
    "    plt.xlabel(\"Integral estimate\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "estimate_integral_variants()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921403a2",
   "metadata": {},
   "source": [
    "## Error Propagation: M/M/1 with Estimated λ, μ\n",
    "\n",
    "Sensitivity Analysis in M/M/1 Queue Simulations\n",
    "\n",
    "In simulations of queueing systems, outputs like the average queue length depend on input parameters such as arrival and service rates. When these parameters are estimated from data, their uncertainty can significantly affect the output. Sensitivity analysis quantifies how changes in these parameters impact the output, helping assess the reliability of simulation results and identify critical parameters. This is vital in applications like operations research or performance modeling, where estimation errors can lead to large variations in predicted performance.\n",
    "\n",
    "This section introduces  sensitivity analysis for an M/M/1 queue, a single-server queueing system with exponential interarrival times (rate $\\lambda$) and service times (rate $\\mu$). We focus on how the expected queue length $L$ is affected by estimation errors in both $\\lambda$ and $\\mu$, using the example with values $\\lambda = 0.8$ and $\\mu = 1.0$.\n",
    "\n",
    "### Why Joint Sensitivity Analysis?\n",
    "\n",
    "In an M/M/1 queue, customers arrive at rate $\\lambda$ (average time between arrivals is $1/\\lambda$) and are served at rate $\\mu$ (average service time is $1/\\mu$). The traffic intensity is $\\rho = \\lambda / \\mu$, and the expected queue length (including the customer being served) is:\n",
    "\n",
    "$L = \\rho / (1 - \\rho)$,\n",
    "\n",
    "valid for $\\rho < 1$ to ensure system stability. In simulations, $\\lambda$ and $\\mu$ are often estimated from data (e.g., interarrival and service times), introducing uncertainty in both parameters. Joint sensitivity analysis examines how errors in $\\hat{\\lambda}$ and $\\hat{\\mu}$ jointly affect $L$, providing a  understanding of the impact of parameter uncertainty, especially when the system is near capacity ((\\rho \\approx 1)).\n",
    "\n",
    "### Sensitivity Analysis Approach\n",
    "\n",
    "***Idea:*** Joint sensitivity analysis computes the partial derivatives of the queue length $L$ with respect to both $\\lambda$ and $\\mu$, denoted $\\partial L / \\partial \\lambda$ and $\\partial L / \\partial \\mu$. These derivatives quantify how small changes in $\\lambda$ or $\\mu$ affect $L$. When $\\lambda$ and $\\mu$ are estimated, we use these sensitivities to approximate the change in $L$ due to estimation errors, often combining them to assess the total impact.\n",
    "\n",
    "The queue length is:\n",
    "\n",
    "$L = \\rho / (1 - \\rho) = (\\lambda / \\mu) / (1 - \\lambda / \\mu) = \\lambda / (\\mu - \\lambda)$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sensitivity to $\\lambda$:\n",
    "\n",
    "Differentiate $L$ with respect to $\\lambda$ (treating $\\mu$ as constant):\n",
    "\n",
    "$\\partial L / \\partial \\lambda = \\mu / (\\mu - \\lambda)^2 = 1 / (1 - \\rho)^2 \\cdot (1 / \\mu)$.\n",
    "\n",
    "This shows that $L$ is highly sensitive to $\\lambda$ when $\\rho$ is close to 1, as $(1 - \\rho)^2$ becomes small.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Sensitivity to $\\mu$:\n",
    "\n",
    "Differentiate $L$ with respect to $\\mu$ (treating $\\lambda$ as constant):\n",
    "\n",
    "$\\partial L / \\partial \\mu = -\\lambda / (\\mu - \\lambda)^2 = -\\rho / (1 - \\rho)^2 \\cdot (1 / \\mu)$.\n",
    "\n",
    "The negative sign indicates that increasing $\\mu$ (faster service) reduces $L$, and the sensitivity is also amplified as $\\rho \\to 1$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Combined Effect:\n",
    "\n",
    "When $\\lambda$ and $\\mu$ are estimated as $\\hat{\\lambda}$ and $\\hat{\\mu}$ with errors $\\Delta \\lambda = \\hat{\\lambda} - \\lambda$ and $\\Delta \\mu = \\hat{\\mu} - \\mu$, the approximate change in $L$ is given by the total differential:\n",
    "\n",
    "$\\Delta L \\approx (\\partial L / \\partial \\lambda) \\Delta \\lambda + (\\partial L / \\partial \\mu) \\Delta \\mu$.\n",
    "\n",
    "Assuming $\\hat{\\lambda}$ and $\\hat{\\mu}$ are estimated from $n$ independent exponential interarrival and service times, their standard errors are $\\text{SE}{\\hat{\\lambda}} = \\hat{\\lambda} / \\sqrt{n}$ and $\\text{SE}{\\hat{\\mu}} = \\hat{\\mu} / \\sqrt{n}$. The variance of $L$ due to parameter uncertainty can be approximated as:\n",
    "\n",
    "$\\text{Var}(L) \\approx (\\partial L / \\partial \\lambda)^2 \\text{Var}(\\hat{\\lambda}) + (\\partial L / \\partial \\mu)^2 \\text{Var}(\\hat{\\mu}) + 2 (\\partial L / \\partial \\lambda) (\\partial L / \\partial \\mu) \\text{Cov}(\\hat{\\lambda}, \\hat{\\mu})$,\n",
    "\n",
    "where $\\text{Cov}(\\hat{\\lambda}, \\hat{\\mu}) = 0$ if interarrival and service times are independent.\n",
    "\n",
    "Example: For an M/M/1 queue with true $\\lambda = 0.8$, $\\mu = 1.0$, we have $\\rho = 0.8$, $L = 0.8 / (1 - 0.8) = 4$. The sensitivities are:\n",
    "\n",
    "$\\partial L / \\partial \\lambda = 1 / (1 - 0.8)^2 \\cdot (1 / 1.0) = 25$,\n",
    "\n",
    "$\\partial L / \\partial \\mu = -0.8 / (1 - 0.8)^2 \\cdot (1 / 1.0) = -20$.\n",
    "\n",
    "Suppose $\\hat{\\lambda} = 0.81$ and $\\hat{\\mu} = 0.99$ (errors $\\Delta \\lambda = 0.01$, $\\Delta \\mu = -0.01$) from $n = 1000$ observations, with standard errors $\\text{SE}{\\hat{\\lambda}} = 0.81 / \\sqrt{1000} \\approx 0.0256$, $\\text{SE}{\\hat{\\mu}} = 0.99 / \\sqrt{1000} \\approx 0.0313$. The change in $L$ is:\n",
    "\n",
    "$\\Delta L \\approx 25 \\cdot 0.01 + (-20) \\cdot (-0.01) = 0.25 + 0.2 = 0.45$,\n",
    "\n",
    "so $L \\approx 4 + 0.45 = 4.45$. The variance of $L$ (assuming independent estimates) is:\n",
    "\n",
    "$\\text{Var}(L) \\approx (25)^2 \\cdot (0.0256)^2 + (-20)^2 \\cdot (0.0313)^2 \\approx 0.409 + 0.392 \\approx 0.801$,\n",
    "\n",
    "with standard deviation $\\sqrt{0.801} \\approx 0.895$, indicating significant uncertainty in $L$ due to parameter estimation errors.\n",
    "\n",
    "Practical Notes: The sensitivities $\\partial L / \\partial \\lambda$ and $\\partial L / \\partial \\mu$ grow rapidly as $\\rho \\to 1$, highlighting the need for precise estimation of both $\\lambda$ and $\\mu$ when the system is near capacity. Plotting these sensitivities for a range of $\\lambda$ and $\\mu$ values (e.g., $\\lambda$ from 0.6 to 0.98, $\\mu = 1.0$) visualizes their impact. In simulations, joint sensitivity analysis guides robust design by quantifying how estimation errors propagate to outputs like $L$, ensuring reliable performance predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bef485",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Simple RNG factory for reproducibility\n",
    "def new_rng(seed):\n",
    "    return np.random.default_rng(seed)\n",
    "\n",
    "# ----------------------------\n",
    "# Discrete-event simulation of an M/M/1 queue\n",
    "# ----------------------------\n",
    "def simulate_mm1(lambda_, mu, T_end=2000.0, seed=123):\n",
    "    \"\"\"\n",
    "    Simulate an M/M/1 queue over [0, T_end] and return the time-average number in system L_hat.\n",
    "    \n",
    "    Event-driven simulation:\n",
    "      - next_arrival: time of next Poisson(λ) arrival\n",
    "      - next_depart:  time of next exponential(μ) service completion (∞ if empty)\n",
    "      - n: number in system\n",
    "      - area: integral of n(t) over time, so L_hat = area / T_end\n",
    "    \"\"\"\n",
    "    rng = new_rng(seed)\n",
    "    t = 0.0               # current time\n",
    "    n = 0                 # number in system\n",
    "    next_arrival = rng.exponential(1 / lambda_)  # first arrival\n",
    "    next_depart = np.inf  # no service scheduled until someone arrives\n",
    "    last_t = 0.0          # last event time\n",
    "    area = 0.0            # integral of n(t): sum over (n * duration between events)\n",
    "\n",
    "    while t < T_end:\n",
    "        # Pick the next event (arrival or depart), whichever happens sooner\n",
    "        if next_arrival <= next_depart:\n",
    "            # Arrival happens next\n",
    "            t = next_arrival\n",
    "            area += n * (t - last_t)   # accumulate area since last event at level n\n",
    "            n += 1                     # one more in the system\n",
    "            last_t = t\n",
    "\n",
    "            # Schedule next arrival\n",
    "            next_arrival = t + rng.exponential(1 / lambda_)\n",
    "            # If the system was empty, this arrival starts service; schedule a departure\n",
    "            if n == 1:\n",
    "                next_depart = t + rng.exponential(1 / mu)\n",
    "        else:\n",
    "            # Departure happens next\n",
    "            t = next_depart\n",
    "            area += n * (t - last_t)\n",
    "            n -= 1\n",
    "            last_t = t\n",
    "\n",
    "            # If still someone left, schedule next departure; otherwise no departure pending\n",
    "            next_depart = t + rng.exponential(1 / mu) if n > 0 else np.inf\n",
    "\n",
    "    # Add remaining rectangle up to T_end\n",
    "    area += n * (T_end - last_t)\n",
    "    return area / T_end  # time-average number in system (ergodic LLN proxy for L)\n",
    "\n",
    "# ----------------------------\n",
    "# Estimation of λ and μ from i.i.d. samples\n",
    "# ----------------------------\n",
    "def estimate_rates(interarrivals, services):\n",
    "    \"\"\"\n",
    "    MLEs for exponential model:\n",
    "      λ̂ = 1 / mean(interarrival times)\n",
    "      μ̂ = 1 / mean(service times)\n",
    "    Standard error (delta method for 1/mean of i.i.d.): SE ≈ θ̂ / sqrt(n)\n",
    "    \"\"\"\n",
    "    lam_hat = 1 / np.mean(interarrivals)\n",
    "    mu_hat  = 1 / np.mean(services)\n",
    "    n_lam, n_mu = len(interarrivals), len(services)\n",
    "    se_lam, se_mu = lam_hat / np.sqrt(n_lam), mu_hat / np.sqrt(n_mu)\n",
    "    return lam_hat, mu_hat, se_lam, se_mu\n",
    "\n",
    "def analytic_L(lambda_, mu):\n",
    "    \"\"\"\n",
    "    M/M/1 steady-state mean number in system:\n",
    "      L = ρ / (1 - ρ),  with ρ = λ / μ and ρ < 1.  (∞ if ρ ≥ 1)\n",
    "    \"\"\"\n",
    "    rho = lambda_ / mu\n",
    "    return np.inf if rho >= 1 else rho / (1 - rho)\n",
    "\n",
    "# ----------------------------\n",
    "# Generate synthetic data for λ and μ estimation\n",
    "# ----------------------------\n",
    "lambda_true, mu_true = 0.8, 1.0\n",
    "n_obs = 1000\n",
    "rng_est = new_rng(2024)\n",
    "\n",
    "# i.i.d. samples consistent with the exponential assumptions of an M/M/1\n",
    "interarrivals = rng_est.exponential(1 / lambda_true, size=n_obs)  # interarrival ~ Exp(λ)\n",
    "services      = rng_est.exponential(1 / mu_true,     size=n_obs)  # service ~ Exp(μ)\n",
    "\n",
    "lam_hat, mu_hat, se_lam, se_mu = estimate_rates(interarrivals, services)\n",
    "\n",
    "print(f'λ_true={lambda_true:.3f}, μ_true={mu_true:.3f} → L_true={analytic_L(lambda_true, mu_true):.3f}')\n",
    "print(f'λ̂={lam_hat:.3f} (SE≈{se_lam:.3f}), μ̂={mu_hat:.3f} (SE≈{se_mu:.3f})')\n",
    "print(f'Plug-in L(λ̂,μ̂)≈{analytic_L(lam_hat, mu_hat):.3f}')\n",
    "\n",
    "# ----------------------------\n",
    "# Baseline: simulation variability with fixed parameters (λ̂, μ̂) only\n",
    "# ----------------------------\n",
    "T_end = 2000.0   # simulation horizon\n",
    "R = 200\n",
    "L_sim_fixed = np.array([\n",
    "    simulate_mm1(lam_hat, mu_hat, T_end=T_end, seed=20_000 + r)\n",
    "    for r in range(R)\n",
    "])\n",
    "print(f'Simulated L (with estimated parameters): mean={L_sim_fixed.mean():.3f}, sd={L_sim_fixed.std(ddof=1):.3f}')\n",
    "\n",
    "# ----------------------------\n",
    "# Sensitivity of L to λ (with μ fixed)\n",
    "# ----------------------------\n",
    "def dL_dlambda(lambda_, mu):\n",
    "    rho = lambda_ / mu\n",
    "    return (1 / mu) * (1 / (1 - rho) ** 2)\n",
    "\n",
    "lambdas = np.linspace(0.6, 0.98, 20)  # approach instability at ρ≈1\n",
    "sens = [dL_dlambda(l, 1.0) for l in lambdas]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(lambdas, sens)\n",
    "plt.xlabel('λ with μ=1')\n",
    "plt.ylabel('Sensitivity ∂L/∂λ')\n",
    "plt.title('Sensitivity grows as ρ → 1')\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# Sensitivity of L to μ (with λ fixed)\n",
    "# ----------------------------\n",
    "def dL_dmu(lambda_, mu):\n",
    "  rho = lambda_ / mu\n",
    "  return (-lambda_ / mu**2) * (1 / (1 - rho)**2)\n",
    "\n",
    "mus = np.linspace(0.85, 1.4, 20)  # vary μ while keeping λ=0.8 fixed\n",
    "sens = [dL_dmu(0.8, m) for m in mus]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mus, sens)\n",
    "plt.xlabel('μ with λ=0.8')\n",
    "plt.ylabel('Sensitivity ∂L/∂μ')\n",
    "plt.title('Sensitivity becomes less negative as μ increases')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f49281",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "- Use inequalities (Markov/Chebyshev/Bernstein) for non-asymptotic guarantees; CLT for tighter approximations.\n",
    "- Diagnose Markov chain convergence; monitor distance to stationarity.\n",
    "- Variance reduction can dramatically reduce simulation effort.\n",
    "- Parameter uncertainty can dominate simulation noise; propagate it explicitly, especially near criticality ($\\rho$ close to 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5233e",
   "metadata": {},
   "source": [
    "## Exercise: M/M/1/K - Birth–Death Process (K=10)\n",
    "Consider a continuous-time birth–death (BD) process mimicking an M/M/1/K queue with capacity $K=10$.\n",
    "- Births (arrivals) occur at rate $\\lambda$ when the state $n<K$; blocked when $n=K$.\n",
    "- Deaths (services) occur at rate $\\mu$ when $n>0$.\n",
    "- States are $n\\in\\{0,1,\\dots,K\\}$.\n",
    "\n",
    "Stationary distribution $\\pi$ solves detailed balance with ratio $\\pi_{n+1}/\\pi_n = \\lambda/\\mu =: \\rho$ for $0\\le n<K$. Hence,\n",
    "- For $\\rho  < 1$: $\\displaystyle \\pi_n = \\frac{1-\\rho}{1-\\rho^{K+1}}\\; \\rho^{n}$, $n=0,\\dots,K$.\n",
    "- For $\\rho = 1$: $\\displaystyle \\pi_n = \\frac{1}{K+1}$.\n",
    "\n",
    "Tasks:\n",
    "1. Implement a function to compute $\\pi$ for given $(\\lambda,\\mu,K)$.\n",
    "2. Implement an event-driven simulator for the BD process in discrete time, and return the average number of item in the queue $\\hat L_n = \\frac{1}n \\sum_{i=0}^N i \\hat \\pi_n (i)$ .\n",
    "3. Convergence: plot $\\lVert \\hat\\pi_n - \\pi \\rVert_1$ as $n$ grows; choose and justify a burn-in $N_{\\text{burn-in}}$. If you are motivated you can identify the second largest (in absolute value) eigenvalue of $P$ and give a theoretical bound on the mixing time. \n",
    "4. Half-width planning: choose the number of replications $N_{\\text{sample}}$ so that the $(1-\\alpha)$ CI half-width for $L$ is at most $\\varepsilon$ (suggest: $\\alpha=0.05$, $\\varepsilon=0.05$).\n",
    "5. Sensitivity: vary $\\lambda$ and $\\mu$ by $\\pm 5\\%$, compare the effect on $L$ and the distribution; relate to $\\partial L/\\partial \\lambda$ intuition. What is the main difference to M/M/1? What kind of measure is more appropriate to consider than $L$? \n",
    "6. The above analysis was done in discrete time, the process observed when an event happened. How can we transfer these estimates to the continous time M/M/1/K process?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff357149",
   "metadata": {},
   "source": [
    "## Exercise: Comparing Antithetic Variates and Standard Simulation in M/M/1 Queue\n",
    "Objective\n",
    "In this exercise, you will implement an M/M/1 queue simulation to estimate the steady-state average queue length (L) using two approaches: a standard Monte Carlo simulation and a simulation with antithetic variates. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278da5dc",
   "metadata": {},
   "source": [
    "#### Instructions and Deliverables\n",
    "Follow these steps. Keep your code clean, modular, and commented.\n",
    "\n",
    "1) Build or adapt an event-driven M/M/1 simulator\n",
    "- Inputs: $(\\lambda,\\mu)$, horizon $T_{\\text{end}}$, burn-in $T_{\\text{burn}}$, RNG/seed.\n",
    "- Output: time-average number in system $L$ computed over $[T_{\\text{burn}}, T_{\\text{end}}]$ and (optionally) the time-average occupancy vector $\\hat\\pi$. \n",
    "\n",
    "2) Standard vs. Antithetic estimators\n",
    "- Standard: draw inter-arrivals $A_i\\sim\\mathrm{Exp}(\\lambda)$ and services $S_j\\sim\\mathrm{Exp}(\\mu)$ in the usual way. \n",
    "- Antithetic: generate uniforms $U_i,V_j\\sim\\mathrm{Unif}(0,1)$ and use pairs $(U_i,1-U_i)$ and $(V_j,1-V_j)$ with $A_i=-\\ln(U_i)/\\lambda$, $A_i'=-\\ln(1-U_i)/\\lambda$ (same for $S_j$).\n",
    "- Implement a simulation that consumes these sequences, producing two paired runs (standard and antithetic counterpart) under identical structural logic. \n",
    "- For the standard run report $\\hat L^{\\text{std}}$; for the antithetic report $\\hat L1, \\hat L_2$ for each run together with the paired average $\\hat L^{\\text{anti}}=\\tfrac{1}{2}(\\hat L_1+\\hat L_2)$.\n",
    "\n",
    "3) Burn-in and convergence\n",
    "- Choose $T_{\\text{burn}}$ based on a quick convergence diagnostic (e.g., run with a long horizon and plot $\\|\\hat\\pi_T-\\pi\\|_1$ vs $T$ or monitor $L$ trajectory).\n",
    "- Justify your choice in 2–3 sentences.\n",
    "\n",
    "4) Replication planning (half-width)\n",
    "- Goal: estimate $\\mathbb E[L]$ with $(1-\\alpha)$ CI half-width $\\le \\varepsilon$ (suggest: $\\alpha=0.05$, $\\varepsilon=0.05$).\n",
    "- Use a pilot of $N_0$ replications to get sample s.d. $s_L$ for standard and antithetic.\n",
    "- Choose $N$ such that $z_{1-\\alpha/2} s_L/\\sqrt{N} \\le \\varepsilon$.\n",
    "- Report the planned $N$ for both methods and use them in the final experiment.\n",
    "\n",
    "5) Variance reduction verification\n",
    "- Run the experiment for both methods; collect $\\{\\hat L^{\\text{std}}_r\\}$ and $\\{\\hat L^{\\text{anti}}_r\\}$.\n",
    "- Report means, standard deviations, and the variance ratio $\\operatorname{Var}(\\hat L^{\\text{anti}})/\\operatorname{Var}(\\hat L^{\\text{std}})$.\n",
    "\n",
    "\n",
    "Checks and tips\n",
    "- Ensure time-average $L$ respects Little's Law via a cross-check when possible.\n",
    "- Antithetic helps most when the output is monotone in the underlying randomness; here, longer services/shorter inter-arrivals increase $L$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_project_env)",
   "language": "python",
   "name": "my_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
