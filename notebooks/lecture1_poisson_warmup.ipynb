{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1 Hands-On: Poisson Warm-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook pairs with Lecture 1. Start with a plain NumPy simulation of Poisson counts, then step into a SimPy arrival process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5039bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import simpy\n",
    "except ImportError as exc:\n",
    "    raise SystemExit(\"SimPy is required for this notebook. Install via 'pip install simpy'.\") from exc\n",
    "\n",
    "RNG = np.random.default_rng(42)\n",
    "NOTEBOOK_DIR = pathlib.Path.cwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a9e0c",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 — Plain Python Warm-Up\n",
    "Follow the checklist from the slides:\n",
    "1. Set the hourly rate `lam` and scale it to a half-hour window.\n",
    "2. Simulate `n_windows = 1_000` Poisson counts for the 30 minute window.\n",
    "3. Report the sample mean and variance versus the theoretical value `lambda_window`.\n",
    "4. Estimate `P(X >= 1)` empirically by counting non-zero draws.\n",
    "5. Summarise the takeaways in the Markdown cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59dd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_per_hour = 4\n",
    "lambda_window = lam_per_hour * 0.5  # TODO: confirm the scaling\n",
    "n_windows = 1_000\n",
    "\n",
    "# TODO: simulate Poisson counts and compute sample mean, variance, and probability of at least one event\n",
    "counts = None\n",
    "sample_mean = None\n",
    "sample_var = None\n",
    "p_ge_one = None\n",
    "p_zero = None  \n",
    "\n",
    "sample_mean, sample_var, p_ge_one, p_zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a419d",
   "metadata": {},
   "source": [
    "### Theoretical Benchmarks\n",
    "\n",
    "For a Poisson random variable $X \\sim \\mathrm{Poi}(\\lambda)$ with $\\lambda = 2$ (half-hour window):\n",
    "- $\\mathbb{E}[X] = \\lambda$.\n",
    "- $\\operatorname{Var}(X) = \\lambda$.\n",
    "- $\\mathbb{P}[X \\ge 1] = 1 - e^{-\\lambda}$.\n",
    "\n",
    "Fill in the following cell to compute the exact values numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab275243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "exact_mean = None\n",
    "exact_variance = None\n",
    "exact_p_ge_one = None\n",
    "eaxct_p_zero = None\n",
    "\n",
    "exact_mean, exact_variance, exact_p_ge_one, eaxct_p_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7907a2c",
   "metadata": {},
   "source": [
    "### Compare Simulation vs. Theory\n",
    "\n",
    "Compute absolute errors between your simulated statistics and the theoretical values above. Check whether the discrepancies are within the tolerance you expect for $n_\\text{windows} = 1000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42f3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace `sample_mean`, `sample_var`, `p_ge_one` after computing them above\n",
    "errors = {\n",
    "    'mean_error': abs(sample_mean - exact_mean),\n",
    "    'variance_error': abs(sample_var - exact_variance),\n",
    "    'prob_error': abs(p_ge_one - exact_p_ge_one),\n",
    "}\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f472fbd9",
   "metadata": {},
   "source": [
    "### Reasonable Tolerance Bounds\n",
    "\n",
    "Determine quantitative tolerances for each statistic. For example, one approach is to use a normal approximation or Chebyshev inequality to set bounds for estimated mean/variance/probabilities. Formulate a justification and verify the simulation output lies within your bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbb2671",
   "metadata": {
    "tags": [
     "tolerance-check"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: Define tolerances justified by your reasoning\n",
    "mean_tolerance = None\n",
    "variance_tolerance = None\n",
    "prob_tolerance = None\n",
    "\n",
    "checks = {\n",
    "    'mean_within_tolerance': errors['mean_error'] <= mean_tolerance if mean_tolerance is not None else None,\n",
    "    'variance_within_tolerance': errors['variance_error'] <= variance_tolerance if variance_tolerance is not None else None,\n",
    "    'prob_within_tolerance': errors['prob_error'] <= prob_tolerance if prob_tolerance is not None else None,\n",
    "}\n",
    "checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2dd3ec",
   "metadata": {},
   "source": [
    "### Commentary\n",
    "\n",
    "Briefly discuss whether the simulation agrees with theory given your tolerances. If it does not, refine your reasoning or increase the number of simulations until the comparison is satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf59d22",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 — M/M/1 Queue in Plain Python\n",
    "\n",
    "We begin with an end-to-end view of the M/M/1 queue before touching SimPy.\n",
    "- **Arrivals** follow a Poisson process with rate $\\lambda$ (exponential inter-arrival times).\n",
    "- **Service times** are i.i.d. exponential with rate $\\mu$.\n",
    "- A single server works first-come/first-served, with unlimited waiting room.\n",
    "\n",
    "Key quantities to track: utilisation $\\rho = \\lambda/\\mu$, waiting times $W_q$, sojourn times $W$, and queue length process $L(t)$. We'll implement a minimal discrete-event simulator using only basic Python + NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Queue and simulation parameters (feel free to tweak)\n",
    "lambda_rate = 4.0   # arrivals per hour\n",
    "mu_rate = 6.0       # services per hour\n",
    "sim_hours = 2.0\n",
    "max_events = 5_000  # safety cap to avoid infinite loops\n",
    "\n",
    "rho = lambda_rate / mu_rate\n",
    "rho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafc594",
   "metadata": {},
   "source": [
    "### Task: Implement a Plain-Python Simulator\n",
    "Steps to follow inside the skeleton below:\n",
    "1. Generate exponential inter-arrival and service times using `rng.exponential` (remember rate vs. scale).\n",
    "2. Keep track of the next arrival time and when the server becomes free.\n",
    "3. For each arrival, decide when service starts (max of arrival time and server-available time), then update departure time.\n",
    "4. Record per-customer metrics: waiting time in queue, total time in system, and queue length just before arrival.\n",
    "5. Stop when simulated time exceeds `sim_hours` or you hit the safety cap.\n",
    "6. Return a dictionary with raw logs to analyse later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bace6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the simulator\n",
    "\n",
    "def simulate_mm1_basic(lambda_rate, mu_rate, sim_hours, rng, max_events=5_000):\n",
    "    \"\"\"Return a dict containing arrival/departure logs for an M/M/1 queue.\"\"\"\n",
    "    raise NotImplementedError\n",
    "\n",
    "mm1_logs = simulate_mm1_basic(lambda_rate, mu_rate, sim_hours, RNG, max_events=max_events)\n",
    "list(mm1_logs.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d6db4",
   "metadata": {},
   "source": [
    "### Theoretical Benchmarks for M/M/1\n",
    "For $\\rho = \\lambda/\\mu < 1$ the steady-state metrics are:\n",
    "- $L = \\dfrac{\\rho}{1-\\rho}$ (expected number in system)\n",
    "- $L_q = \\dfrac{\\rho^2}{1-\\rho}$ (expected number waiting)\n",
    "- $W = \\dfrac{1}{\\mu - \\lambda}$ (expected time in system)\n",
    "- $W_q = \\dfrac{\\rho}{\\mu - \\lambda}$ (expected waiting time)\n",
    "\n",
    "Compute them numerically below for the chosen parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98661bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical = {\n",
    "    'L': rho / (1 - rho),\n",
    "    'L_q': (rho**2) / (1 - rho),\n",
    "    'W': 1 / (mu_rate - lambda_rate),\n",
    "    'W_q': rho / (mu_rate - lambda_rate),\n",
    "}\n",
    "theoretical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b42ea4",
   "metadata": {},
   "source": [
    "### Analyse the Simulation Output\n",
    "Using the raw logs, derive empirical estimates for the same metrics:\n",
    "- Average number in system / queue (e.g., via time averaging or Little's Law).\n",
    "- Sample means for waiting time and total time in system.\n",
    "Then compare to the theoretical values above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6a6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: derive empirical metrics from mm1_logs\n",
    "empirical = {\n",
    "    'L_est': None,\n",
    "    'L_q_est': None,\n",
    "    'W_est': None,\n",
    "    'W_q_est': None,\n",
    "}\n",
    "empirical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf2ef43",
   "metadata": {},
   "source": [
    "### Sanity Check\n",
    "Compute absolute errors between empirical estimates and theory. Comment on whether the run length (`sim_hours`) and sample size are enough to match steady-state predictions, and what adjustments you would make if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compare empirical metrics to theory (once filled)\n",
    "if all(value is not None for value in empirical.values()):\n",
    "    mm1_errors = {\n",
    "        'L_error': abs(empirical['L_est'] - theoretical['L']),\n",
    "        'L_q_error': abs(empirical['L_q_est'] - theoretical['L_q']),\n",
    "        'W_error': abs(empirical['W_est'] - theoretical['W']),\n",
    "        'W_q_error': abs(empirical['W_q_est'] - theoretical['W_q']),\n",
    "    }\n",
    "else:\n",
    "    mm1_errors = None\n",
    "mm1_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a07deb",
   "metadata": {},
   "source": [
    "### Reflection\n",
    "Summarise your findings: does the simple simulator agree with the closed-form M/M/1 results? Note any sources of discrepancy (finite horizon, warm-up bias, random fluctuation) and proposed fixes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d6edf",
   "metadata": {},
   "source": [
    "### From Analytical Models to Event Simulation\n",
    "Parts 1 and 2 gave us the arrival distribution and queue behaviour using plain NumPy. We now carry those ingredients into SimPy so that the event scheduling matches the assumptions we've already validated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d9c7c7",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3 — SimPy Arrival Stream\n",
    "Recreate the same Poisson arrival process inside SimPy. Treat this as the event-driven counterpart to the NumPy simulations:\n",
    "1. Reuse `lam_per_hour` from Part 1 for the arrival rate.\n",
    "2. Implement `arrival_process(env, lam, rng, log)` that draws exponential inter-arrival times (matching Part 1) and records `env.now` just like the timestamps you computed for M/M/1.\n",
    "3. Write `simulate_arrivals` that seeds a SimPy environment, launches the process, and runs it for `duration_hours`.\n",
    "4. After the run, analyse the timestamps to recover **both** the inter-arrival distribution and the half-hour counts. Compare these to the theoretical benchmarks from Part 1 and use the tolerances you developed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b808a04",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "lam = lam_per_hour  # reuse the rate from Part 1\n",
    "window_hours = 0.5\n",
    "num_windows = int(duration_hours / window_hours) if 'duration_hours' in globals() else 4\n",
    "simpy_duration_hours = 2.0\n",
    "simpy_rng = RNG  # reuse the global RNG unless you prefer a fresh seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b35076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the arrival process and simulation driver\n",
    "def arrival_process(env, lam, rng, log):\n",
    "    raise NotImplementedError\n",
    "\n",
    "def simulate_arrivals(lam, duration_hours, rng):\n",
    "    raise NotImplementedError\n",
    "\n",
    "arrival_log = simulate_arrivals(lam, simpy_duration_hours, simpy_rng)\n",
    "arrival_log[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa74af8",
   "metadata": {},
   "source": [
    "### Analyse the Arrival Log\n",
    "- Compute inter-arrival samples and verify their mean/variance against the exponential theory ($1/\\lambda$).\n",
    "- Bucket arrivals into half-hour windows and compare empirical counts to the Part 1 metrics (mean, variance, $P(X\\ge 1)$, etc.).\n",
    "- Comment on whether the SimPy results respect the tolerances you set earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: derive inter-arrival times, compute summary statistics, and produce at least one plot\n",
    "# Suggested structure:\n",
    "# 1. inter_arrivals = np.diff(arrival_log)\n",
    "# 2. counts = ... (e.g., np.histogram or manual binning per half-hour)\n",
    "# 3. Compare to `exact_mean`, `exact_variance`, `exact_p_ge_one`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2abbd8",
   "metadata": {},
   "source": [
    "### Stretch Goal\n",
    "Replace the manual M/M/1 simulator with a SimPy version: inject the same arrivals into a SimPy `Resource`, add exponential services with rate `mu_rate`, and replicate the queueing metrics from Part 2. Compare the two implementations and explain any differences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
