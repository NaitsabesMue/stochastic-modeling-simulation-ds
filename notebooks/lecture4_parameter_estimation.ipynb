{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 Hands-On: Parameter Estimation\n",
    "\n",
    "This notebook accompanies Lecture 4. We estimate parameters for Poisson processes, M/M/1 queues, and M/G/1 queues. We also build plug-in estimators for performance metrics and quantify uncertainty via asymptotic CIs and bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Poisson rate MLE from counts on [0, T]; CI and coverage.\n",
    "- M/M/1: estimate $\\lambda$ from arrivals and $\\mu$ from service samples or busy-time exposure; plug-in $W_q, L$.\n",
    "- M/G/1: estimate $\\lambda$, service moments $(m_1, m_2)$; Pollaczek–Khinchine plug-in for $\\mathbb E[W_q]$ with CI (delta or bootstrap).\n",
    "- Discuss stability (\\rho < 1) and near-critical sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d298cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "from typing import Tuple\n",
    "try:\n",
    "    from scipy.stats import norm\n",
    "    def z_critical(alpha: float=0.05) -> float:\n",
    "        # Compute critical z-value for two-sided CI\n",
    "        return float(norm.ppf(1.0 - alpha/2.0))\n",
    "except Exception:\n",
    "    def z_critical(alpha: float=0.05) -> float:\n",
    "        # Fallback to 1.96 for 95% if scipy unavailable\n",
    "        return 1.959963984540054 if abs(alpha-0.05)<1e-9 else 1.96\n",
    "\n",
    "def ci_two_sided(est: float, se: float, alpha: float=0.05) -> Tuple[float,float]:\n",
    "    # Compute two-sided (1-alpha) CI\n",
    "    z = z_critical(alpha)\n",
    "    return est - z*se, est + z*se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef96f4",
   "metadata": {},
   "source": [
    "### What we'll do\n",
    "\n",
    "- Model: homogeneous Poisson process observed on [0, T].\n",
    "- Task: MLE of the rate (λ̂ = N(T)/T), derive a 95% CI, and check coverage by repetition.\n",
    "- Takeaway: counts-and-exposure are sufficient; exact variance is λ/T; CI stabilises as T grows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93318dd",
   "metadata": {},
   "source": [
    "## Part A — Poisson Rate Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4cfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_poisson_process(lam: float, T: float, rng=np.random.default_rng()):\n",
    "    # Simulate Poisson process with rate lam up to time T\n",
    "    t = 0.0\n",
    "    times = []\n",
    "    while True:\n",
    "        t += rng.exponential(1.0/lam)\n",
    "        if t > T:\n",
    "            break\n",
    "        times.append(t)\n",
    "    return np.array(times)\n",
    "\n",
    "def poisson_mle_from_counts(n_events: int, T: float):\n",
    "    # MLE for Poisson rate lambda from n_events in time T\n",
    "    lam_hat = n_events / T\n",
    "    se = math.sqrt(max(lam_hat, 1e-12) / T)\n",
    "    lo, hi = ci_two_sided(lam_hat, se)\n",
    "    return lam_hat, (lo, hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918ebe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-run demo\n",
    "lam_true, T = 0.8, 1000.0\n",
    "times = simulate_poisson_process(lam_true, T, rng)\n",
    "lam_hat, (lo, hi) = poisson_mle_from_counts(len(times), T)\n",
    "print(f'True λ={lam_true:.3f},  n={len(times)},  T={T}')\n",
    "print(f'λ̂={lam_hat:.4f},  95% CI=({lo:.4f}, {hi:.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c50ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage experiment (modest size for runtime)\n",
    "def coverage_poisson(lam_true=0.8, T=200.0, reps=500, seed=123):\n",
    "    r = np.random.default_rng(seed)\n",
    "    cover = 0\n",
    "    for _ in range(reps):\n",
    "        n = len(simulate_poisson_process(lam_true, T, r))\n",
    "        lam_hat, (lo, hi) = poisson_mle_from_counts(n, T)\n",
    "        cover += (lo <= lam_true <= hi)\n",
    "    return cover / reps\n",
    "\n",
    "cov = coverage_poisson()\n",
    "print(f'Empirical 95% CI coverage ≈ {100*cov:.1f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf081819",
   "metadata": {},
   "source": [
    "## Part B — M/M/1: Estimating $\\lambda$ and $\\mu$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0e7aaf",
   "metadata": {},
   "source": [
    "### What we'll do\n",
    "\n",
    "- Observation schemes: (A) i.i.d. inter-arrivals/services; (B) calendar-time aggregates ($N_A(T)$, $C(T)$, busy time $B(T$)).\n",
    "- Estimation: $\\hat λ$ from counts/exposure, $\\hat \\mu$ from completions per busy-time; plug into M/M/1 formulae.\n",
    "- Diagnostics: compare plug-in $W_q$ to empirical mean wait; consider burn-in and near-critical sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class MM1Stats:\n",
    "    \"\"\"Simulation statistics for a single-server queue.\n",
    "    arrivals: count of arrivals with arrival_time <= T\n",
    "    completions: count of completions by time T\n",
    "    busy_time: total server busy time within [0, T]\n",
    "    T: observation horizon\n",
    "    service_samples: array of service times actually started\n",
    "    waits: array of waiting times (Wq) for completed jobs\n",
    "    \"\"\"\n",
    "    arrivals: int\n",
    "    completions: int\n",
    "    busy_time: float\n",
    "    T: float\n",
    "    service_samples: np.ndarray\n",
    "    waits: np.ndarray\n",
    "\n",
    "def simulate_MM1(T: float, lam: float, mu: float, rng=np.random.default_rng()):\n",
    "    \"\"\"Simulate an M/M/1 queue on [0, T] with exponential(λ) inter-arrivals and exponential(μ) services.\n",
    "    Returns MM1Stats with waits (Wq) and service_samples recorded.\n",
    "    \"\"\"\n",
    "    t = 0.0\n",
    "    next_arrival = t + rng.exponential(1.0/lam)\n",
    "    server_busy = False\n",
    "    service_end = math.inf\n",
    "    queue = []              # FIFO queue of arrival timestamps\n",
    "    waits = []              # waiting times before service (Wq)\n",
    "    service_samples = []    # service times actually started\n",
    "    arrivals = 0\n",
    "    completions = 0\n",
    "    busy_time = 0.0\n",
    "    busy_start = None\n",
    "\n",
    "    def start_service(now):\n",
    "        nonlocal server_busy, service_end, busy_start\n",
    "        s = rng.exponential(1.0/mu)\n",
    "        service_samples.append(s)\n",
    "        server_busy = True\n",
    "        busy_start = now\n",
    "        return now + s\n",
    "\n",
    "    while True:\n",
    "        t_next = min(next_arrival, service_end)\n",
    "        if t_next == math.inf:\n",
    "            break\n",
    "        t = t_next\n",
    "\n",
    "        if next_arrival <= service_end:  # arrival\n",
    "            if t <= T:\n",
    "                arrivals += 1\n",
    "                if server_busy:\n",
    "                    queue.append(t)\n",
    "                else:\n",
    "                    waits.append(0.0)  # no waiting when server idle\n",
    "                    service_end = start_service(t)\n",
    "            next_arrival = t + rng.exponential(1.0/lam)\n",
    "        else:  # completion\n",
    "            if busy_start is not None and busy_start < T:\n",
    "                busy_time += max(0.0, min(t, T) - busy_start)\n",
    "                busy_start = None\n",
    "            if t <= T:\n",
    "                completions += 1\n",
    "            if queue:\n",
    "                a = queue.pop(0)\n",
    "                waits.append(max(0.0, t - a))\n",
    "                busy_start = t\n",
    "                service_end = start_service(t)\n",
    "            else:\n",
    "                server_busy = False\n",
    "                service_end = math.inf\n",
    "        if next_arrival > T and not server_busy and t >= T:\n",
    "            break\n",
    "\n",
    "    if server_busy and busy_start is not None and busy_start < T:\n",
    "        busy_time += max(0.0, T - busy_start)\n",
    "\n",
    "    return MM1Stats(arrivals=arrivals, completions=completions, busy_time=busy_time, T=T,\n",
    "                    service_samples=np.array(service_samples), waits=np.array(waits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M/M/1 experiment\n",
    "# We simulate on [0, T], compute λ̂ from arrivals/exposure, μ̂ from completions per busy-time,\n",
    "# and compare plug-in Wq to empirical mean wait (Wq).\n",
    "lam_true, mu_true = 0.8, 1.0  # true parameters (λ, μ)  # ρ=0.8\n",
    "T = 1000.0\n",
    "stats = simulate_MM1(T, lam_true, mu_true, rng)\n",
    "lam_hat = stats.arrivals / stats.T  # λ̂ from arrivals per unit time\n",
    "mu_hat_busy = stats.completions / max(stats.busy_time, 1e-12)  # μ̂ from completions per busy-time\n",
    "mu_hat_sample = len(stats.service_samples) / max(stats.service_samples.sum(), 1e-12)  # alternative μ̂ from service samples\n",
    "\n",
    "# Asymptotic SEs\n",
    "se_lam = math.sqrt(max(lam_hat, 1e-12) / stats.T)\n",
    "se_mu_busy = math.sqrt(max(mu_hat_busy, 1e-12) / max(stats.busy_time, 1e-12))\n",
    "se_mu_sample = mu_hat_sample / math.sqrt(max(len(stats.service_samples), 1,))\n",
    "\n",
    "def ci(x, se, alpha=0.05):\n",
    "    lo, hi = ci_two_sided(x, se, alpha)\n",
    "    return (lo, hi)\n",
    "\n",
    "print(f'M/M/1 on [0,T], T={T}')\n",
    "print(f'True λ={lam_true:.3f}, μ={mu_true:.3f};  observed arrivals={stats.arrivals}, completions={stats.completions}, busy_time={stats.busy_time:.1f}')\n",
    "print(f'λ̂={lam_hat:.4f}  CI95={ci(lam_hat,se_lam)}')\n",
    "print(f'μ̂ (busy-time) ={mu_hat_busy:.4f}  CI95={ci(mu_hat_busy,se_mu_busy)}')\n",
    "print(f'μ̂ (from samples)={mu_hat_sample:.4f}  CI95={ci(mu_hat_sample,se_mu_sample)}')\n",
    "\n",
    "# Plug-in performance\n",
    "rho_hat = lam_hat / mu_hat_busy  # utilization estimate\n",
    "Wq_hat = lam_hat / (mu_hat_busy * (mu_hat_busy - lam_hat))  # M/M/1 formula\n",
    "Wq_true = lam_true / (mu_true * (mu_true - lam_true))\n",
    "Wq_emp = stats.waits.mean() if stats.waits.size else 0.0  # empirical mean wait (Wq)\n",
    "den = mu_hat_busy * max(mu_hat_busy - lam_hat, 1e-12)\n",
    "dlam = (mu_hat_busy**2) / (den**2)\n",
    "dmu  = -lam_hat * (2*mu_hat_busy - lam_hat) / (den**2)\n",
    "var_lam = max(lam_hat, 1e-12) / stats.T\n",
    "var_mu  = max(mu_hat_busy, 1e-12) / max(stats.busy_time, 1e-12)\n",
    "var_wq  = dlam**2 * var_lam + dmu**2 * var_mu\n",
    "se_wq   = math.sqrt(max(var_wq, 0.0))\n",
    "wq_lo, wq_hi = ci_two_sided(Wq_hat, se_wq, alpha=0.05)\n",
    "print(f'True Wq={Wq_true:.4f},  Plug-in Wq̂={Wq_hat:.4f} (CI95=[{wq_lo:.4f},{wq_hi:.4f}]),  Empirical avg wait≈{Wq_emp:.4f}')\n",
    "\n",
    "# Plot waiting time histogram\n",
    "plt.figure(figsize=(5.2,3.4))\n",
    "plt.hist(stats.waits, bins=40, alpha=0.7, color='tab:blue', density=True)\n",
    "plt.axvline(Wq_true, color='tab:green', lw=1.8, label=f'True Wq={Wq_true:.2f}')\n",
    "plt.axvline(Wq_hat, color='tab:orange', lw=1.8, label=f'Plug-in Wq̂={Wq_hat:.2f}')\n",
    "plt.axvline(Wq_emp, color='tab:red', lw=1.8, label=f'Empirical Wq={Wq_emp:.2f}')\n",
    "plt.axvspan(wq_lo, wq_hi, color='tab:orange', alpha=0.15, label=f'Plug-in 95% CI')\n",
    "plt.title('M/M/1 Waiting Time Histogram with Benchmarks')\n",
    "plt.xlabel('Wq'); plt.ylabel('Density'); plt.grid(True, alpha=0.3); plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e1b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn-in analysis for M/M/1 (ignore first 10% of completed jobs)\n",
    "burn = int(0.10*len(stats.waits))\n",
    "if stats.waits.size == 0:\n",
    "    Wq_emp_all = float('nan')\n",
    "    Wq_emp_tail = float('nan')\n",
    "else:\n",
    "    Wq_emp_all = float(np.mean(stats.waits))\n",
    "    Wq_emp_tail = float(np.mean(stats.waits[burn:])) if len(stats.waits) > burn else Wq_emp_all\n",
    "print(f'Empirical mean wait (all)   = {Wq_emp_all:.4f}')\n",
    "print(f'Empirical mean wait (90%)   = {Wq_emp_tail:.4f}')\n",
    "print(f'Plug-in Wq (M/M/1, busy μ̂) = {Wq_hat:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9401ce23",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "- Plug-in vs empirical can differ on finite runs; the difference shrinks with longer T and after discarding initial transients.\n",
    "- Near ρ→1, small parameter errors amplify Wq (derivatives blow up). Report uncertainty and check stability (ρ̂<1).\n",
    "- Using busy-time exposure for μ̂ aligns with the MLE under Scheme B and is preferable to 1/mean(S) when only aggregates are available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513eac45",
   "metadata": {},
   "source": [
    "## Part C — M/G/1: Moment Estimation and PK Plug-in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861a661",
   "metadata": {},
   "source": [
    "### What we'll do\n",
    "\n",
    "- Estimate λ, m1, m2 from data; compute the PK plug-in Wq = λ m2 / (2(1−ρ)).\n",
    "- Two CIs: Delta method (asymptotic) and input bootstrap (PK only).\n",
    "- Important: input bootstrap ≠ system bootstrap; we add a regenerative bootstrap later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79583232",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure simulate_MG1_gamma is defined (fallback if notebook executed out of order)\n",
    "if 'simulate_MG1_gamma' not in globals():\n",
    "    def simulate_MG1_gamma(T: float, lam: float, shape: float, scale: float, rng=np.random.default_rng()):\n",
    "        t = 0.0\n",
    "        next_arrival = t + rng.exponential(1.0/lam)\n",
    "        server_busy = False\n",
    "        service_end = math.inf\n",
    "        queue = []\n",
    "        waits = []\n",
    "        service_samples = []\n",
    "        arrivals = 0\n",
    "        completions = 0\n",
    "        busy_time = 0.0\n",
    "        busy_start = None\n",
    "        def start_service(now):\n",
    "            nonlocal server_busy, service_end, busy_start\n",
    "            s = rng.gamma(shape=shape, scale=scale)\n",
    "            service_samples.append(s)\n",
    "            server_busy = True\n",
    "            busy_start = now\n",
    "            return now + s\n",
    "        while True:\n",
    "            t_next = min(next_arrival, service_end)\n",
    "            if t_next == math.inf:\n",
    "                break\n",
    "            t = t_next\n",
    "            if next_arrival <= service_end:\n",
    "                if t <= T:\n",
    "                    arrivals += 1\n",
    "                    if server_busy:\n",
    "                        queue.append(t)\n",
    "                    else:\n",
    "                        waits.append(0.0)  # no wait when server idle\n",
    "                        service_end = start_service(t)\n",
    "                next_arrival = t + rng.exponential(1.0/lam)\n",
    "            else:\n",
    "                if busy_start is not None and busy_start < T:\n",
    "                    busy_time += max(0.0, min(t, T) - busy_start)\n",
    "                    busy_start = None\n",
    "                if t <= T:\n",
    "                    completions += 1\n",
    "                if queue:\n",
    "                    a = queue.pop(0)\n",
    "                    waits.append(max(0.0, t - a))\n",
    "                    busy_start = t\n",
    "                    service_end = start_service(t)\n",
    "                else:\n",
    "                    server_busy = False\n",
    "                    service_end = math.inf\n",
    "            if next_arrival > T and not server_busy and t >= T:\n",
    "                break\n",
    "        if server_busy and busy_start is not None and busy_start < T:\n",
    "            busy_time += max(0.0, T - busy_start)\n",
    "        return MM1Stats(arrivals=arrivals, completions=completions, busy_time=busy_time, T=T,\n",
    "                        service_samples=np.array(service_samples), waits=np.array(waits))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11573b0b",
   "metadata": {},
   "source": [
    "### Part C — M/G/1 with Gamma service: what we estimate\n",
    "\n",
    "- We simulate M/G/1 with Poisson(λ) inter-arrivals and Gamma(shape, scale) services; we record zero waits when service starts immediately.\n",
    "- Estimate λ̂ from counts/exposure, m̂1, m̂2 from service samples; compute PK plug-in Wq̂ and its Delta-method CI.\n",
    "- Compare with empirical mean wait; finite-horizon effects and variability can cause gaps that shrink with longer T and burn-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b49fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Gamma service with mean 1 and variance 0.5 -> shape=2, scale=0.5\n",
    "shape, scale = 2.0, 0.5\n",
    "m1_true = shape*scale\n",
    "m2_true = (shape*scale)**2 + shape*scale**2\n",
    "lam_true = 0.7\n",
    "rho_true = lam_true * m1_true\n",
    "assert rho_true < 1\n",
    "T = 20000.0\n",
    "stats_mg1 = simulate_MG1_gamma(T, lam_true, shape, scale, rng)\n",
    "\n",
    "lam_hat = stats_mg1.arrivals / stats_mg1.T\n",
    "S = stats_mg1.service_samples\n",
    "m1_hat = S.mean()\n",
    "m2_hat = (S**2).mean()\n",
    "rho_hat = lam_hat * m1_hat\n",
    "Wq_true = lam_true * m2_true / (2*(1 - rho_true))\n",
    "Wq_hat = lam_hat * m2_hat / (2*(1 - rho_hat))\n",
    "Wq_emp = stats_mg1.waits.mean() if stats_mg1.waits.size else 0.0\n",
    "# Delta-method CI for PK plug-in (λ, m1, m2)\n",
    "nS = len(S)\n",
    "rho_hat = lam_hat * m1_hat\n",
    "g_lam = m2_hat / (2.0 * (1.0 - rho_hat)**2)\n",
    "g_m1  = (lam_hat**2) * m2_hat / (2.0 * (1.0 - rho_hat)**2)\n",
    "g_m2  = lam_hat / (2.0 * (1.0 - rho_hat))\n",
    "var_lam = max(lam_hat, 1e-12) / stats_mg1.T\n",
    "var_S   = float(np.var(S, ddof=1)) if nS>1 else 0.0\n",
    "S2      = S**2\n",
    "var_S2  = float(np.var(S2, ddof=1)) if nS>1 else 0.0\n",
    "cov_S_S2 = float(np.cov(S, S2, ddof=1)[0,1]) if nS>1 else 0.0\n",
    "var_m1 = var_S / max(nS,1)\n",
    "var_m2 = var_S2 / max(nS,1)\n",
    "cov_m1_m2 = cov_S_S2 / max(nS,1)\n",
    "var_wq = (g_lam**2)*var_lam + (g_m1**2)*var_m1 + (g_m2**2)*var_m2 + 2*g_m1*g_m2*cov_m1_m2\n",
    "se_wq = math.sqrt(max(var_wq, 0.0))\n",
    "wq_lo_gamma, wq_hi_gamma = ci_two_sided(Wq_hat, se_wq, alpha=0.05)\n",
    "print(f'Gamma service: m1_true={m1_true:.3f}, m2_true={m2_true:.3f},  ρ_true={rho_true:.3f}')\n",
    "print(f'λ̂={lam_hat:.4f}, m1̂={m1_hat:.4f}, m2̂={m2_hat:.4f},  ρ̂={rho_hat:.4f}')\n",
    "print(f'Wq_true={Wq_true:.4f},  Plug-in Wq̂={Wq_hat:.4f} (CI95=[{wq_lo_gamma:.4f},{wq_hi_gamma:.4f}]),  Empirical avg wait≈{Wq_emp:.4f}')\n",
    "\n",
    "# Bootstrap CI for Wq plug-in\n",
    "def bootstrap_Wq(S, lam_hat, B=300, seed=123):\n",
    "    r = np.random.default_rng(seed)\n",
    "    n = len(S)\n",
    "    out = np.empty(B)\n",
    "    for b in range(B):\n",
    "        Sb = r.choice(S, size=n, replace=True)\n",
    "        m1b = Sb.mean()\n",
    "        m2b = (Sb**2).mean()\n",
    "        rhob = lam_hat * m1b\n",
    "        out[b] = lam_hat * m2b / (2 * max(1e-9, (1 - rhob)))\n",
    "    lo, hi = np.percentile(out, [2.5, 97.5])\n",
    "    return (lo, hi), out\n",
    "\n",
    "(lo, hi), samples = bootstrap_Wq(S, lam_hat)\n",
    "print(f'Bootstrap 95% CI for PK plug-in Wq: ({lo:.4f}, {hi:.4f})')\n",
    "\n",
    "plt.figure(figsize=(5.2,3.4))\n",
    "plt.hist(samples, bins=40, alpha=0.75, color='tab:green', density=True)\n",
    "plt.axvline(Wq_hat, color='k', lw=1.5, label='Plug-in Wq̂')\n",
    "plt.axvline(Wq_emp, color='tab:red', lw=1.5, label='Empirical mean wait')\n",
    "plt.title('Bootstrap distribution of Wq plug-in (M/G/1)')\n",
    "plt.xlabel('Wq'); plt.ylabel('Density'); plt.grid(True, alpha=0.3); plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Wait-time histogram with PK plug-in CI band\n",
    "plt.figure(figsize=(5.2,3.4))\n",
    "plt.hist(stats_mg1.waits, bins=40, alpha=0.7, color='tab:purple', density=True)\n",
    "plt.axvline(Wq_true, color='tab:green', lw=1.8, label=f'True Wq={Wq_true:.2f}')\n",
    "plt.axvline(Wq_hat, color='tab:orange', lw=1.8, label=f'PK plug-in={Wq_hat:.2f}')\n",
    "plt.axvline(Wq_emp, color='tab:red', lw=1.8, label=f'Empirical Wq={Wq_emp:.2f}')\n",
    "plt.axvspan(wq_lo_gamma, wq_hi_gamma, color='tab:orange', alpha=0.15, label='PK plug-in 95% CI')\n",
    "plt.title('M/G/1 (Gamma) Waiting Time Histogram with Benchmarks')\n",
    "plt.xlabel('Wq'); plt.ylabel('Density'); plt.grid(True, alpha=0.3); plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bd7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Burn-in analysis for M/G/1 (Gamma) using job order (approximate)\n",
    "burn = int(0.10*len(stats_mg1.waits))\n",
    "Wq_emp_all = stats_mg1.waits.mean() if stats_mg1.waits.size else float('nan')\n",
    "Wq_emp_tail = stats_mg1.waits[burn:].mean() if stats_mg1.waits.size>burn else float('nan')\n",
    "print(f'Empirical mean wait (all)   = {Wq_emp_all:.4f}')\n",
    "print(f'Empirical mean wait (90%)   = {Wq_emp_tail:.4f}')\n",
    "print(f'PK plug-in Wq               = {Wq_hat:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a400cc9",
   "metadata": {},
   "source": [
    "## Part D — Case Study: Identify and Fit a Queue Model from Data\n",
    "\n",
    "Scenario\n",
    "\n",
    "A single-agent support chat handles tickets during a business window. A triage tool and internal SOP enforce **bounded handling times** (SLA). The system logs for each ticket: arrival_time, service_time, start_service_time, completion_time, wait_time, system_time, and queue_len_at_arrival.\n",
    "You are given the raw log `data/lecture4_case_study.csv`. The observation is contiguous (no gaps), though mild time-of-day effects may exist.\n",
    "\n",
    "Goal\n",
    "\n",
    "- From the data alone, **infer a plausible single-server queue model** (e.g., M/M/1, M/G/1 with a bounded or heavy-tailed family, or GI/G/1).\n",
    "- Justify assumptions, quantify fit, and discuss limitations.\n",
    "\n",
    "Hints\n",
    "\n",
    "- Bounded service suggests a **Uniform or truncated** family may be reasonable; verify with histograms/ECDF and summary stats.\n",
    "- Check whether inter-arrivals are **Poisson-like**: exponential inter-arrival distribution, and a roughly constant rate over time (or segment by time-of-day if needed).\n",
    "- Compute **utilisation** $\\hat \\rho = \\hat \\lambda \\hat m_1$ and ensure $\\hat \\rho<1$.\n",
    "- Compare empirical mean wait to a model-based prediction (e.g., M/M/1 formula or M/G/1 PK if you choose that model).\n",
    "- Use **regenerative bootstrap** (busy cycles) to form a system-level CI for mean wait; use **input bootstrap** only if you assume a PK plug-in.\n",
    "- Iterate: refine the chosen service family (Uniform, Gamma, Lognormal, truncated variants), or question Poisson arrivals if rate varies strongly.\n",
    "\n",
    "Deliverables\n",
    "\n",
    "- A concise write-up: your chosen model, evidence (plots/statistics), fitted parameters, and two CIs (input PK if relevant; regenerative).\n",
    "- Short discussion of alternative models you considered and why they were rejected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, os\n",
    "CANDIDATES=['data/lecture4_case_study.csv']\n",
    "DATA_PATH=next((p for p in CANDIDATES if os.path.exists(p)), None)\n",
    "assert DATA_PATH, 'Missing case study CSV'\n",
    "df=pd.read_csv(DATA_PATH)\n",
    "print(f'Loaded dataset: {DATA_PATH} with {len(df)} rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ee2e8",
   "metadata": {},
   "source": [
    "#### Checklist\n",
    "- [ ] Nonnegative waits and start ≥ arrival\n",
    "- [ ] Inter-arrival diagnostics (histograms/ECDF, stationarity)\n",
    "- [ ] Service diagnostics (boundedness, candidate families)\n",
    "- [ ] Estimated $\\hat \\lambda, \\hat m_1, \\hat m_2, \\hat \\rho$ with $\\hat \\rho <1$\n",
    "- [ ] Model-based Wq vs empirical Wq with CIs\n",
    "- [ ] Regenerative bootstrap CI for mean wait\n",
    "- [ ] Clear justification of the chosen model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvLLMDS (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
